{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52299a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No error was detected files successfully compiled\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "from datetime import datetime, timedelta\n",
    "from calendar import monthrange\n",
    "import os\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import re\n",
    "import openpyxl \n",
    "import math\n",
    "\n",
    "\n",
    "### Creation of final table column names ###\n",
    "\n",
    "original_column_names = ['19G1_MW', '19G1_MX', '19G1_KV', '19G1_AMPS', '19G1_AMPS2', '19G1_VOLTS', '19G1_PF', '19G1_RPM', '19G1_GP', '19G1_AVR_BAL', '19G1_Trans_Temp', '19G1_TR_WDG']\n",
    "# Initialize a list to store new column names\n",
    "column_names = ['Date&Time']\n",
    "\n",
    "number_of_units = 4\n",
    "\n",
    "# Iterate over original column names \n",
    "for i in range(1,number_of_units + 1):\n",
    "    for column_name in original_column_names:  \n",
    "        # Change 'G1' to 'G2', 'G3', 'G4' for subsequent duplicates\n",
    "        new_name = column_name.replace('G1', 'G' + str(i))\n",
    "        column_names.append(new_name)\n",
    "\n",
    "# Create DataFrame with new column names\n",
    "all_sheets_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "### Excel File Processing and Validation Functions for Creating DataFrames For The Raw Data ###\n",
    "\n",
    "# Create a list of visible sheet names from an .xls file\n",
    "def read_visible_sheets_xls(file_path):\n",
    "    visible_sheet_names = []\n",
    "    with xlrd.open_workbook(file_path) as workbook:\n",
    "        for sheet_name in pd.ExcelFile(file_path).sheet_names:\n",
    "            sheet = workbook.sheet_by_name(sheet_name)\n",
    "            if not sheet.visibility:\n",
    "                visible_sheet_names.append(sheet_name)\n",
    "    return visible_sheet_names\n",
    "\n",
    "# Create a list of visible sheet names from an .xlsx file\n",
    "def read_visible_sheets_xlsx(file_path):\n",
    "    visible_sheet_names = []\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "        if sheet.sheet_state == 'visible':\n",
    "            visible_sheet_names.append(sheet_name)\n",
    "    return visible_sheet_names\n",
    "\n",
    "# Function to check if a date string is in the valid \"dd-mm-yy\" format\n",
    "def is_valid_date(date_str):\n",
    "    try:\n",
    "        datetime.strptime(date_str, \"%d-%m-%y\")\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Function to filter and return valid sheet names based on valid date format\n",
    "def check_valid_dates(sheet_names):\n",
    "    invalid_dates = []\n",
    "    for date in sheet_names:\n",
    "        if not is_valid_date(date):\n",
    "            invalid_dates.append(date)\n",
    "    valid_sheet_names = [item for item in sheet_names if item not in invalid_dates]\n",
    "    return valid_sheet_names\n",
    "\n",
    "# Function to check that the valid sheets cover all dates in the given month and identify any missing or extra dates\n",
    "def check_date_sequence(month, year,valid_sheets):\n",
    "    year = int(year)\n",
    "    num_days = monthrange(year, month)[1]\n",
    "    dates = []\n",
    "    for day in range(1, num_days + 1):\n",
    "        dates.append(\"{:02d}-{:02d}-{}\".format(day, month, str(year)[2:]))\n",
    "        \n",
    "    set_sheets = set(valid_sheets)\n",
    "    set_dates = set(dates)\n",
    "    missing_in_sheets = set(dates) - set(valid_sheets)\n",
    "    missing_in_dates = set(valid_sheets) - set(dates)\n",
    "    if dates == valid_sheets:\n",
    "        check = True\n",
    "    else:\n",
    "        if missing_in_sheets:\n",
    "            check = False\n",
    "            print(\"Missing dates:\",missing_in_sheets)\n",
    "        if missing_in_dates:\n",
    "            check = False\n",
    "            print(\"Invalid dates:\",missing_in_dates)\n",
    "    return check\n",
    "\n",
    "# Function to read .xls file format into a DataFrame, excluding hidden rows and columns\n",
    "def read_excel_sheet_to_df_xls(sheet, file_path):\n",
    "    try:\n",
    "        workbook = xlrd.open_workbook(file_path, formatting_info=True)\n",
    "        xl_sheet = workbook.sheet_by_name(sheet)\n",
    "        data = []\n",
    "        for irow in range(min(xl_sheet.nrows, 50)):\n",
    "            irow_hidden = xl_sheet.rowinfo_map[irow].hidden   # Row Visibility 0=Visible 1=Hidden\n",
    "            row_data = []\n",
    "            for icol in range(xl_sheet.ncols):  # Iterate through all columns in the row\n",
    "                if icol in xl_sheet.colinfo_map:\n",
    "                    icol_hidden = xl_sheet.colinfo_map[icol].hidden   # Column Visibility 0=Visible 1=Hidden\n",
    "                    col_width = xl_sheet.colinfo_map[icol].width\n",
    "                else:\n",
    "                    icol_hidden = False  # Column is not explicitly hidden\n",
    "                    col_width = 2340\n",
    "                if not irow_hidden and not icol_hidden and col_width > 100:\n",
    "                    svalue = xl_sheet.cell(irow, icol).value\n",
    "                    row_data.append(svalue)\n",
    "            # Only append unhidden rows to the data list\n",
    "            if not irow_hidden:\n",
    "                data.append(row_data)\n",
    "        # Create a DataFrame from the unhidden rows\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"An error1 occurred:\", e)\n",
    "        return None\n",
    "\n",
    "# Function to read .xlsx file format into a DataFrame, excluding hidden rows and columns\n",
    "def read_excel_sheet_to_df_xlsx(sheet, file_path):\n",
    "    try:\n",
    "        # Function to convert Excel column name to numerical value\n",
    "        def column_to_number(column):\n",
    "            number = 0\n",
    "            for char in column:\n",
    "                number = number * 26 + (ord(char) - 64)\n",
    "            return number - 1\n",
    "\n",
    "        # Read Excel file as Pandas DataFrame\n",
    "        df = pd.read_excel(file_path, sheet_name = sheet )\n",
    "        \n",
    "        # Open an Excel workbook\n",
    "        workbook = openpyxl.load_workbook(file_path)\n",
    "\n",
    "        # Create a `Worksheet` object \n",
    "        worksheet = workbook[sheet]\n",
    "\n",
    "        # List of indices corresponding to all hidden rows\n",
    "        hidden_rows_idx = [\n",
    "            row - 2\n",
    "            for row, dimension in worksheet.row_dimensions.items() \n",
    "            if dimension.hidden\n",
    "        ]\n",
    "\n",
    "        # List of indices corresponding to all hidden columns with width less than 1\n",
    "        hidden_cols_idx = [\n",
    "            column_to_number(col_name) \n",
    "            for col_name, dimension in worksheet.column_dimensions.items() \n",
    "            if dimension.hidden or dimension.width < 1\n",
    "        ]\n",
    "\n",
    "        # Find names of columns corresponding to hidden column indices\n",
    "        hidden_cols_name = df.columns[hidden_cols_idx].tolist()\n",
    "\n",
    "        # Drop the hidden columns\n",
    "        df.drop(hidden_cols_name, axis=1, inplace=True)\n",
    "\n",
    "        # Drop the hidden rows\n",
    "        df.drop(hidden_rows_idx, axis=0, inplace=True)\n",
    "\n",
    "        # Reset the index\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"An error1 occurred\", e)\n",
    "        return None\n",
    "\n",
    "### DataFrame Cleaning, Formatting, and Relevant Data Extraction Through Validation Checks Functions ###\n",
    "\n",
    "# Extracts and cleans the initial plant readings data from the sheet.\n",
    "def clean_dataframe1(df):\n",
    "    try:\n",
    "        time_index = df[df.iloc[:,0] == \"TIME\"].index\n",
    "        if len(time_index)>0:\n",
    "            start_index = time_index[0]\n",
    "            end_index = start_index + 26\n",
    "\n",
    "            df = df.iloc[start_index:end_index]\n",
    "\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            expected_numbers = list(range(1,25))\n",
    "            first_column_values = df.iloc[2:, 0].tolist()\n",
    "\n",
    "            if not first_column_values == expected_numbers:\n",
    "                incorrect_index = next((i+2 for i, value in enumerate(first_column_values) if value != i+1), None)\n",
    "\n",
    "                if incorrect_index is not None:\n",
    "                    for i in range(incorrect_index, len(df)):\n",
    "                        if pd.notna(df.iloc[i-1,0]) and isinstance(df.iloc[i-1,0], (int,float)):\n",
    "                            df = df.copy()\n",
    "                            df.iloc[i, 0] = df.iloc[i-1, 0] + 1\n",
    "                            \n",
    "        # Step 1: Ensure consecutive numbers from 1 to 24 in the first column\n",
    "        expected_numbers = list(range(1, 25))\n",
    "        if df.iloc[2:, 0].tolist() == expected_numbers:\n",
    "            # Replace empty strings with NaN\n",
    "            df = df.replace(r'^\\s*$', np.nan, regex=True).copy()  \n",
    "            \n",
    "            # Drop columns containing \"Calculated\" where the rest of the items in that column are NaN\n",
    "            cols_to_drop = df.columns[df.apply(lambda col: col.astype(str).str.contains('Calculated').any())]\n",
    "            filtered_cols_to_drop = []\n",
    "            for column_name in cols_to_drop:\n",
    "                if df.loc[2:,column_name].apply(lambda x: isinstance(x, str) or pd.isna(x)).all():\n",
    "                    filtered_cols_to_drop.append(column_name)               \n",
    "            df = df.drop(columns=filtered_cols_to_drop)          \n",
    "            # Drop columns with only NaN values\n",
    "            df = df.dropna(axis=1, how='all')                              \n",
    "        else:\n",
    "            print(f\"Sheet {sheet} in file {file_name} has an error in their hour order\")\n",
    "            df = None\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"An error2 occurred:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_column_index(df):\n",
    "    try:\n",
    "        if df is not None:\n",
    "            # Initialize variables to track the occurrences of \"MW\" and \"WINDING\"\n",
    "            first_MW_index = None\n",
    "            second_MW_index = None\n",
    "            third_MW_index = None\n",
    "            fourth_MW_index = None\n",
    "            fourth_WINDING_index = None\n",
    "\n",
    "            # Counter for tracking the number of occurrences found\n",
    "            occurrence_count1 = 0\n",
    "            occurrence_count2 = 0\n",
    "            # Iterate over the columns of the DataFrame\n",
    "            for column in df.columns:\n",
    "                # Iterate over the values in each column\n",
    "                for index, value in enumerate(df[column]):\n",
    "                    if value == \"MW\":\n",
    "                        if first_MW_index is None:\n",
    "                            first_MW_index = df.columns.get_loc(column)\n",
    "                            occurrence_count1 += 1\n",
    "                        elif second_MW_index is None:\n",
    "                            second_MW_index = df.columns.get_loc(column)\n",
    "                            occurrence_count1 += 1\n",
    "                        elif third_MW_index is None:\n",
    "                            third_MW_index = df.columns.get_loc(column)\n",
    "                            occurrence_count1 += 1\n",
    "                        elif fourth_MW_index is None:\n",
    "                            fourth_MW_index = df.columns.get_loc(column)\n",
    "                            occurrence_count1 += 1\n",
    "                        if occurrence_count1 == 4:  # If all four occurrences are found, exit the loop\n",
    "                            break\n",
    "                    elif value == \"WINDING\":\n",
    "                        occurrence_count2 += 1\n",
    "                        # Update WINDING index if it's the fourth occurrence\n",
    "                        if occurrence_count2 == 4:\n",
    "                            fourth_WINDING_index = df.columns.get_loc(column) + 1\n",
    "                            break\n",
    "                if occurrence_count1 == 4 and fourth_WINDING_index is not None:\n",
    "                    break\n",
    "\n",
    "            # Store the values in a dictionary\n",
    "            result = {\n",
    "                \"first_MW_index\": first_MW_index,\n",
    "                \"second_MW_index\": second_MW_index,\n",
    "                \"third_MW_index\": third_MW_index,\n",
    "                \"fourth_MW_index\": fourth_MW_index,\n",
    "                \"fourth_WINDING_index\": fourth_WINDING_index\n",
    "            }\n",
    "        else:\n",
    "            result = None\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(\"An error3 occurred:\", e)\n",
    "        return None\n",
    "        \n",
    "#This function determines the indices of key columns (\"MW\" and \"WINDING\") in the DataFrame, which helps in dividing the plant readings into two sections and verifying the order of column headings\n",
    "\n",
    "def section_check(section_index,df,section,sheet):\n",
    "    try:\n",
    "        if section_index is not None:\n",
    "            if section == 1:\n",
    "                # Define the pattern to search for\n",
    "                pattern = re.compile(r'MW|MX|KV|AMP|FIELD', re.IGNORECASE)\n",
    "                # Labels to check against\n",
    "                labels = ['MW', 'MX', 'KV', 'AMP', 'FIELD']\n",
    "                # Variable to track if labels match\n",
    "                labels_match = True\n",
    "                a = 5\n",
    "                b = 0\n",
    "            elif section == 2:\n",
    "                # Define the pattern to search for\n",
    "                pattern = re.compile(r'POWER|RPM|GATE|AVR|OIL|WINDING', re.IGNORECASE)\n",
    "                # Labels to check against\n",
    "                labels = ['POWER', 'RPM', 'GATE', 'AVR', 'OIL','WINDING']\n",
    "                # Variable to track if labels match\n",
    "                labels_match = True\n",
    "                a = 8\n",
    "                b = - 6\n",
    "            sheet_dict = {sheet: []}\n",
    "            for key, column in section_index.items():\n",
    "                # Variable to track the last index of each label seen\n",
    "                last_index = {label: None for label in labels}\n",
    "                \n",
    "                iterations = a  # Number of iterations to the left\n",
    "                count = 0\n",
    "                # Loop through columns from start_column_index to the left for the specified number of iterations\n",
    "                current_index = column + b\n",
    "                while count < iterations:\n",
    "                    # Check if the column index exists within df.columns\n",
    "                    if df.columns[current_index] in df.columns:\n",
    "                        for i in range(2):  # Iterate through the first two rows\n",
    "                            cell_value = str(df.iloc[i,current_index])\n",
    "                            match = pattern.search(cell_value)  # Search for pattern match\n",
    "                            if match:\n",
    "                                matched_label = match.group().upper()  # Get the matched label and convert to uppercase\n",
    "                                if last_index[matched_label] is None:\n",
    "                                    last_index[matched_label] = current_index\n",
    "                        current_index +=1\n",
    "                        count +=1\n",
    "                    else:\n",
    "                        # Handle the case where the column index does not exist in df.columns\n",
    "                        print(\"Column index\", current_index, \"does not exist in df.columns.\")\n",
    "                        break\n",
    "                        \n",
    "                first_key, current_index = next(iter(last_index.items()))\n",
    "                if None not in last_index.values() and current_index < 50:\n",
    "                    for index, (key, value) in enumerate(last_index.items()):\n",
    "                        if index > 0:  # Skip the first element\n",
    "                            if value == current_index + 1:\n",
    "                                current_index = value\n",
    "                            else:\n",
    "                                labels_match = False\n",
    "                                break\n",
    "                        if not labels_match:\n",
    "                            break  # Break the outer loop if mismatch found\n",
    "                    if not labels_match:\n",
    "                        break  # Break the outer loop if mismatch\n",
    "                else:\n",
    "                    key_with_none_value = next(key for key, value in last_index.items() if value is None)\n",
    "                    print(f\"The key '{key_with_none_value}' has a value of None.\")\n",
    "                    labels_match = False\n",
    "                if labels_match:\n",
    "                    sheet_dict[sheet].append(list(last_index.values()))\n",
    "\n",
    "            if not labels_match:\n",
    "                sheet_dict = None\n",
    "                print(\"Correct heading arrangement\")\n",
    "\n",
    "        return sheet_dict\n",
    "    except Exception as e:\n",
    "        print(f\"{sheet}: An error4 occurred:{e}\")\n",
    "        return None\n",
    "\n",
    "# Extracts and formats date from the given sheet name\n",
    "def format_date(sheet,year):\n",
    "    try:\n",
    "        parts = sheet.split('-')\n",
    "        \n",
    "        # Convert parts to integers\n",
    "        day = int(parts[0])\n",
    "        month = int(parts[1])\n",
    "        year = year[2:]\n",
    "        \n",
    "        # Convert back to strings and format them\n",
    "        formatted_date = \"{:02d}/{:02d}/{}\".format(month, day, year)\n",
    "        return formatted_date\n",
    "    except Exception as e:\n",
    "        print(\"An error5 occurred:\", e)\n",
    "        return None\n",
    "\n",
    "# Generates and appends hourly timestamps to the 'Date&Time' column of the FInal DataFrame based on the provided formatted date\n",
    "def append_date_time(formatted_date, all_sheets_df):\n",
    "    try:\n",
    "        num_rows = len(all_sheets_df)\n",
    "        # Split the string by '-'\n",
    "        \n",
    "        for hour in range(1, 25):\n",
    "            index = hour - 1\n",
    "            if hour == 24:\n",
    "                date_format = \"%m/%d/%y\"\n",
    "                date = datetime.strptime(formatted_date, date_format)\n",
    "                next_day = date + timedelta(days=1)\n",
    "                next_day_str = next_day.strftime(date_format)\n",
    "                timestamp = f\"{next_day_str} 00:00\"\n",
    "            else:\n",
    "                timestamp = f\"{formatted_date} {hour:02}:00\"\n",
    "            all_sheets_df.at[index + num_rows, 'Date&Time'] = timestamp\n",
    "        return all_sheets_df\n",
    "    except Exception as e:\n",
    "        print(\"An error6 occurred:\", e)\n",
    "        return None\n",
    "\n",
    "# This function identifies the column indices that contain voltage readings for the four units\n",
    "def get_volt_index(combined_index,df,sheet):\n",
    "    try:\n",
    "        volt_indices = [ ]\n",
    "        combined_values = combined_index[sheet]\n",
    "        indices = [4,5,15,16,26,27,37,38]\n",
    "        volts_index = [combined_values[index] for index in indices]\n",
    "        \n",
    "        # Iterate through pairs of indices\n",
    "        count = 0\n",
    "        volt_dict={}\n",
    "        for i in range(0, len(volts_index), 2):\n",
    "            start_index = volts_index[i]\n",
    "            end_index = volts_index[i + 1]\n",
    "\n",
    "            # Find numbers between the pairs\n",
    "            volt_dict[i] = [ ]\n",
    "            for num in range(start_index + 1, end_index):\n",
    "                volt_dict[i].append(num)\n",
    "                count +=1\n",
    "            if start_index + 1 == end_index:\n",
    "                count += 1\n",
    "        volt_count = count\n",
    "        for key,value in volt_dict.items():\n",
    "            if not volt_dict[key]:\n",
    "                volt_dict[key].append(np.nan)\n",
    "                #print(sheet)    \n",
    "            if volt_count <= 4:\n",
    "                volt_indices.append(value[0])\n",
    "            elif volt_count > 4:\n",
    "                if len(value) > 1:\n",
    "                    vcount = 0\n",
    "                    vidx = [ ]\n",
    "                    for col_idx in value:\n",
    "                        check = df.iloc[2:, col_idx]\n",
    "                        has_number = False\n",
    "                        for val in check:\n",
    "                            if isinstance(val, (int, float)) and not math.isnan(val):\n",
    "                                has_number = True\n",
    "                                break\n",
    "                        if has_number:\n",
    "                            vcount += 1\n",
    "                            vidx.append(col_idx)\n",
    "                    \n",
    "                    if vcount == 1:\n",
    "                        volt_indices.append(vidx[0])\n",
    "                        \n",
    "                    elif vcount == 0:\n",
    "                        volt_indices.append(value[0])\n",
    "                else:\n",
    "                    volt_indices.append(value[0])            \n",
    "        return volt_indices\n",
    "    except Exception as e:\n",
    "        print(f\"An error7 occurred in {sheet}:\", e)\n",
    "        return None\n",
    "\n",
    "#This function generates the final processed DataFrame by combining data from the voltage sections and the combined data sections\n",
    "def append_data(combined_index, df, all_sheets_df,formatted_date,volt_indices):\n",
    "    try:\n",
    "        for idx, date_time in all_sheets_df['Date&Time'].items():\n",
    "            if formatted_date + \" 01:00\" in date_time:\n",
    "                start_index = idx\n",
    "                break\n",
    "        index1 = 0\n",
    "        index2 = 0\n",
    "        for column_name in all_sheets_df.columns[1:]:\n",
    "            if \"VOLTS\" not in column_name.upper():\n",
    "                column_index1 = combined_index[sheet][index1]\n",
    "                data_to_copy = df.iloc[2:, column_index1]\n",
    "                all_sheets_df.loc[start_index:start_index + len(data_to_copy), column_name] = data_to_copy.values\n",
    "                index1 += 1\n",
    "            elif \"VOLTS\" in column_name.upper() and len(volt_indices) == 4:\n",
    "                column_index2 = volt_indices[index2]\n",
    "                if np.isnan(column_index2):\n",
    "                    data_to_copy = pd.Series([np.nan] * 24)\n",
    "                else:\n",
    "                    data_to_copy = df.iloc[2:, column_index2]\n",
    "                all_sheets_df.loc[start_index:start_index + len(data_to_copy), column_name] = data_to_copy.values\n",
    "                index2 += 1\n",
    "        return all_sheets_df\n",
    "    except Exception as e:\n",
    "        print(\"An error8 occurred:\", e)\n",
    "        return None\n",
    "\n",
    "### Reading Excel Files to Start the Data Extraction Process ###\n",
    "months_order = {\n",
    "    'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n",
    "    'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12\n",
    "}\n",
    "\n",
    "# Prompt the user to enter the folder path\n",
    "folder_path = input(\"Please enter the folder path containing the Excel files: \")\n",
    "sorted_file_names = sorted(file_names, key=lambda x: (months_order[x[0:3]]))\n",
    "error_detected = True\n",
    "\n",
    "### Process and Extract Data from Excel Files in the Specified Folder ###\n",
    "# Loop through files in the folder\n",
    "for file_name in sorted_file_names:\n",
    "    year_index = file_name.find('20')\n",
    "    year = file_name[year_index:year_index+4]\n",
    "    month = months_order[file_name[0:3]]\n",
    "    # Check if the file is an Excel file\n",
    "    if file_name.endswith('.xlsx') or file_name.endswith('.xls'):      \n",
    "        file_type = 'xlsx' if file_name.endswith('.xlsx') else 'xls'\n",
    "        \n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "  \n",
    "        if file_type == 'xls':\n",
    "\n",
    "            # Read visible sheets\n",
    "            sheet_names = read_visible_sheets_xls(file_path)\n",
    "            \n",
    "        elif file_type == 'xlsx':\n",
    "        \n",
    "            # Read visible sheets\n",
    "            sheet_names = read_visible_sheets_xlsx(file_path)\n",
    "\n",
    "        # Check valid dates\n",
    "        valid_sheets = check_valid_dates(sheet_names)        \n",
    "        \n",
    "        check_date = check_date_sequence(month, year,valid_sheets)\n",
    "        if check_date == False:\n",
    "            error_detected = False\n",
    "        \n",
    "        for sheet in valid_sheets:\n",
    "            if file_type == 'xls':\n",
    "                df = read_excel_sheet_to_df_xls(sheet, file_path)\n",
    "            \n",
    "            elif file_type == 'xlsx':\n",
    "                df = read_excel_sheet_to_df_xlsx(sheet, file_path)\n",
    "                \n",
    "            df = clean_dataframe1(df)\n",
    "            \n",
    "            formatted_date = format_date(sheet,year)\n",
    "            \n",
    "            all_sheets_df = append_date_time(formatted_date, all_sheets_df)\n",
    "            \n",
    "            if df is not None:\n",
    "                \n",
    "                column_index = find_column_index(df)\n",
    "            \n",
    "            else:\n",
    "                column_index = None\n",
    "            \n",
    "            if column_index is not None:\n",
    "\n",
    "                first_section_index = dict(list(column_index.items())[:4])\n",
    "\n",
    "                first_section = section_check(first_section_index,df,1,sheet)\n",
    "\n",
    "                second_section_index = dict(list(column_index.items())[1:5])\n",
    "\n",
    "                second_section = section_check(second_section_index,df,2,sheet)\n",
    "            \n",
    "            else:\n",
    "                first_section = None\n",
    "                second_section =  None\n",
    "                \n",
    "            if first_section is not None and second_section is not None:\n",
    "\n",
    "                # Initialize combined_index dictionary\n",
    "                combined_index = {}\n",
    "\n",
    "                # Iterate over the keys of first_section_index and second_section_index (assuming they have the same keys)\n",
    "                for key in first_section.keys():\n",
    "                    # Combine the lists of column indices while maintaining the order\n",
    "                    combined_index[key] = sum(first_section[key] + second_section[key], [])\n",
    "                    # Sorting the combined_index\n",
    "                    combined_index[key].sort()  \n",
    "                volt_indices = get_volt_index(combined_index,df,sheet)\n",
    "                \n",
    "                if len(volt_indices) == 4: \n",
    "                    final_sheets_df = append_data(combined_index, df, all_sheets_df,formatted_date,volt_indices)\n",
    "                    \n",
    "                else:\n",
    "                    error_detected = False\n",
    "                    print(f\"Correct Volt Column in {sheet} {file_name}\\n\")\n",
    "                \n",
    "                if final_sheets_df is not None:\n",
    "                    all_sheets_df = final_sheets_df\n",
    "                else:\n",
    "                    error_detected = False\n",
    "                    print(f\"Error in {sheet} {file_name}\\n\")\n",
    "            else:\n",
    "                error_detected = False\n",
    "                print(f\"Error in {sheet} {file_name}\\n\")\n",
    "\n",
    "### Final DataFrame Validation and Export to Excel ###\n",
    "if error_detected: \n",
    "    print(\"No error was detected files successfully compiled\")\n",
    "    \n",
    "    for column_name in all_sheets_df.columns[1:]:\n",
    "        for i in range(len(all_sheets_df)):\n",
    "            if isinstance(all_sheets_df[column_name].iloc[i], str) and not any(char.isdigit() for char in all_sheets_df[column_name].iloc[i]):\n",
    "                all_sheets_df.at[i, column_name] = np.nan\n",
    "\n",
    "    all_sheets_df.to_excel(f'{year} Compiled.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f030d-e2c9-4c67-ba53-576d3252187c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
